{"challenge":{"announcements":[],"are_results_final":true,"end_ms":1493551800000,"hide_scoreboard":false,"hide_scoreboard_config":{},"id":"0000000000201842","is_practice_available":true,"my_user_type":1,"my_user_type__str":"SPECTATOR","recap":"<p>\n  The last of our Round 1 sub-rounds is over! A further 1000 contestants have\n  advanced to Round 2 and Distributed Round 1. For those of you who did not\n  advance, we hope that you found the Round 1 problems enjoyable, and we\n  certainly hope to see you back next year!\n</p><p>\n  This round featured <i>Ample Syrup</i>, a surprise additional pancake-themed\n  problem for 2017. Although it was superficially geometry-based, it was really\n  more about reducing the complexity of a search space.\n  <i>Parenting Partnering</i> was inspired by real life events on the Code\n  Jam team; to solve it, it helped to think carefully about intervals and have\n  a greedy insight. Finally, <i>Core Training</i> was a bit of a wild card. The\n  first dataset is tractable, and solving it provides a hint toward the solution\n  of the second dataset, but getting there still required some tricky observations\n  and perhaps some experimentation.  Even with multiple attempts allowed, less than\n  1% of the people who solved the first dataset went on to solve the second one\n  correctly!\n</p><p>\n  Slightly more than 1000 coders scored 57 points or better, which is the score achieved\n  for solving both datasets for the first two problems, so almost all of those people will\n  advance to the next round.\n</p><p>\n  EgorKulikov won the round, solving all three problems with a time of 43:59.  Seven more\n  coders also got a perfect score of 100.\n</p>\n<hr>\n<p>\n  <b>Cast</b>\n</p><p>\n  Problem A (Ample Syrup): Written by Pablo Heiber and Ian Tullis. Prepared by\n  John Dethridge.\n</p><p>\n  Problem B (Parenting Partnering): Written by Pablo Heiber. Prepared by Ian\n  Tullis.\n</p><p>\n  Problem C (Core Training): Written by David Arthur and Ian Tullis. Prepared\n  by Ahmed Aly.\n</p><p>\n  Solutions and other problem preparation and review by Md Mahbubul Hasan, Brian Hirashiki,\n  Lalit Kundu, Petr Mitrichev, Rohan Mukkamala, Trung Thanh Nguyen, and Erick\n  Wong.\n</p><p>\n  Analysis authors:\n</p>\n<ul>\n  <li>Ample Syrup: Ian Tullis</li>\n  <li>Parenting Partnering: Ian Tullis</li>\n  <li>Core Training: David Arthur, Pablo Heiber, and Ian Tullis</li>\n</ul>","registration_gives_participant":false,"result_status":30,"result_status__str":"FINALIZED","start_ms":1493542800000,"tasks":[{"analysis":"<h2>Core Training: Analysis</h2>\n<h3>Small dataset</h3>\n<p>\n  In the Small dataset, every core must succeed. The probability that this will\n  happen is the product of the success probabilities of the individual cores:\n  <b>P<sub>0</sub></b> &times; <b>P<sub>1</sub></b> &times; ... &times;\n  <b>P<sub><b>N</b>-1</sub></b>. How can we assign our training units to\n  maximize that product?\n</p><p>\n  We will show that it is always best for us to spend our units on the core\n  with the lowest success probability. Suppose that <b>P<sub>0</sub></b> &lt;\n  <b>P<sub>1</sub></b>, and we have some tiny amount Q of units to spend; we\n  will denote <b>P<sub>2</sub></b> &times; ... &times;\n  <b>P<sub><b>N</b>-1</sub></b> as OtherStuff. If we spend the Q units to\n  improve <b>P<sub>0</sub></b>, our success probability becomes\n  (<b>P<sub>0</sub></b> + Q) &times; <b>P<sub>1</sub></b> &times; OtherStuff.\n  If we instead improve <b>P<sub>1</sub></b>, the product becomes\n  <b>P<sub>0</sub></b> &times; (<b>P<sub>1</sub></b> + Q) &times; OtherStuff.\n  Expanding those expressions, we find that they are identical, except that the\n  first has a Q &times; <b>P<sub>1</sub></b> &times; OtherStuff term where the\n  second has a Q &times; <b>P<sub>0</sub></b> &times; OtherStuff term. Since we\n  know that <b>P<sub>0</sub></b> &lt; <b>P<sub>1</sub></b>, the first value\n  must be larger. This means that we should improve <b>P<sub>0</sub></b> first.\n</p><p>\n  The argument above has one issue to iron out: what if increasing\n  <b>P<sub>0</sub></b> causes it to rise above <b>P<sub>1</sub></b>? By\n  the same argument, we should switch to improving <b>P<sub>1</sub></b> instead\n  at the instant that <b>P<sub>0</sub></b> exceeds <b>P<sub>1</sub></b>, and\n  vice versa if they change ranks again, and so on. So, once we have made\n  <b>P<sub>0</sub></b> equal to <b>P<sub>1</sub></b>, we should increase both\n  of them at the same time. More generally, we should increase the smallest\n  probability until it exactly matches the next smallest probability, then\n  increase those at the same time until they exactly match the next smallest,\n  and so on. We could try to simulate adding tiny units bit by bit, but it is\n  faster to directly calculate how many units are spent at each step. We must\n  take care to correctly handle the case in which we do not have enough units\n  to fully complete a step.\n</p>\n<h3>Large dataset</h3>\n<p>\n  In the Large dataset, <b>K</b> of the cores must succeed. Now it is no longer\n  necessarily optimal to improve the smallest probability. For example, suppose\n  that <b>N</b> = 2, <b>K</b> = 1, and <b>U</b> = 0.01, and the\n  <b>P<sub>i</sub></b> values for the two cores are 0.99 and 0.01. If we spend\n  all of our 0.01 units on the first core, its success probability becomes 1\n  and we succeed regardless of whether the second core succeeds. There is no\n  reason to consider spending any units on the second core.\n</p><p>\n  Let's extend this strategy of investing most heavily in a subset of the cores\n  and ignoring the rest. We will sort the cores' success probabilities from\n  lowest to highest, and focus on the ones from some index i onward. As in the\n  Small solution, we will start by improving the success probability of the\n  core at index i to match the success probability of the core at index i+1,\n  then improve those two until they match the success probability of the core\n  at index i+2, and so on. (If all of the success probabilities including and\n  beyond index i become 1, then we can improve the core at index i-1, and so\n  on.) We will show that, for some value of i, this is the optimal strategy.\n  We can then try every possibility for i and keep the one that yields the\n  largest overall answer. Notice that, for one optimal i, at most one\n  \"previous\" core i-1 needs to be improved, because there is at most\n  one i such that capacity is enough to improve\n  cores i, i+1, ..., <b>N</b> up to probability 1 and have some left\n  to improve i-1 but not up to 1 (otherwise, we can just choose\n  i-1 instead).\n</p><p>\n  First, let us consider whether it is better to improve core i or core\n  i+1. Let A<sub>i</sub> and B<sub>i</sub> be the probability of exactly\n  <b>K</b>-2 and <b>K</b>-1, respectively, of the cores\n  1, 2, ..., i - 1, i + 2, i + 3, ..., <b>N</b> succeeding. Let\n  P<sub>i,d</sub> be the probability of at least <b>K</b> cores succeding\n  if the success probability of core i is P<sub>i</sub>+d and the\n  probability of success of any other core j is P<sub>j</sub>.\n  By replacing the definitions and cancelling out some values, we\n  can see that P<sub>i,d</sub> - P<sub>i+1,d</sub> =\n  (A<sub>i</sub> - B<sub>i</sub>) &times;\n  (P<sub>i+1</sub> - P<sub>i</sub>) &times; d.\n  Since (P<sub>i+1</sub> - P<sub>i</sub>) &times; d is positive,\n  improving core i+1 is better than improving core i if and only if\n  B<sub>i</sub> &gt; A<sub>i</sub>. Moreover, this doesn't depend on\n  the initial success probabilities of cores i+1 and i, but only on their\n  relative values. So, if we improve core i+1 a little bit, it is still better\n  to keep improving core i+1 if we can instead of switching to improve core i.\n</p><p>\n  Now we want to show that there is some i<sub>0</sub> such that\n  B<sub>i</sub> &gt; A<sub>i</sub> if and only if i &ge; i<sub>0</sub>.\n  That i<sub>0</sub> is the core where we want to start improving.\n  Notice that A<sub>i</sub> depends on <b>N</b>-2 probabilities,\n  and A<sub>i+1</sub> depends on other <b>N</b>-2 cores, but\n  <b>N</b>-3 of those overlap. Assume fixed <b>N</b>-3 core probabilities\n  and let A(p) be the probability that exactly <b>K</b>-1 of the <b>N</b>-3\n  fixed cores and an additional core with probability p succed.\n  Define B(p) similarly. We will show that\n  A(p + d) - B(p + d) &gt; A(p) - B(p) for all p and d.\n  Let U, V and W be the probabilities of having exactly <b>K</b>-3,\n  <b>K</b>-2 and <b>K</b>-1 successes out of the fixed <b>N</b>-3 cores.\n  Then, A(p) = U &times; p + V &times; (1 - p) and\n  B(p) = V &times; p + W &times; (1 - p). Then, B(p) - A(p) is a linear\n  function on p, which means if it ever changes from positive to\n  negative, it must be B(0) - A(0) &gt; 0 and B(1) - A(1) &lt; 0, which\n  implies W &gt; V and V &lt; U. However, this is impossible, because it\n  is a well known fact in probability theory that the function f(k)\n  defined as the number of successes in a given set of independent\n  experiments is convex, so it has no local minimum at <b>K</b>-2.\n</p><p>\n  With the above claim established, we can check all possible values of i and\n  then take the largest overall success probability that we find. To compute\n  the probability of at least K successes, we can use a dynamic programming\n  method similar to the one described in the analysis\n  for last year's Red Tape Committee problem.\n</p><p>\n  It is difficult to prove this method under time pressure in a contest, but we\n  can discover it via brute force simulation, e.g., by dividing up the\n  available units into quanta and exploring all possible ways to partition them\n  among a small number of cores, and seeing which assignment yields the\n  greatest chance of success. It is also possible to arrive at the correct\n  answers via other methods such as\n  <a href=\"https://en.wikipedia.org/wiki/Gradient_descent\" target=\"_blank\">gradient descent</a>.\n</p>\n","id":"00000000002017f2","statement":"<h3>Problem</h3>\n<p>\n  Writing Code Jam problems is hard, so we have built an AI to come up with new\n  ideas. To make the AI as creative as possible, we have given it <b>N</b>\n  different \"cores\", each of which has its own \"personality\". However, just\n  like people, these cores may become distracted or corrupt or may refuse to\n  work; the i-th core has a <i>success probability</i> <b>P<sub>i</sub></b> of\n  functioning properly. As long as at least <b>K</b> of the cores function\n  properly, the AI will function properly. Otherwise, it will probably become\n  evil and trap us in a maze of fiendish puzzles of its own design. And who\n  knows what it might do to Code Jam &mdash; it might just write a bunch of\n  tough probability problems!\n</p><p>\n  To prevent this from happening, we plan to train one or more of the cores to\n  become more reliable. We have a total of <b>U</b> \"training units\" that we\n  can use to improve the cores. Spending X units on the i-th core will\n  add X to its success probability. We can divide up the units among the\n  cores however we like, and it is possible that one or more cores may not\n  receive any units. Of course, a core's success probability cannot be\n  increased above 1.\n</p><p>\n  If we assign the training units to maximize the probability that the AI will\n  function properly, what is that probability?\n</p>\n\n<h3>Solving this problem</h3>\n<p>\n  This problem has 2 Small datasets and no Large dataset. You must solve the\n  first Small dataset before you can attempt the second Small dataset. You will\n  be able to retry either of the datasets (with a time penalty).\n</p>\n\n<h3>Input</h3>\n<p>\n  The first line of the input gives the number of test cases, <b>T</b>.\n  <b>T</b> test cases follow; each consists of three lines. The first line\n  contains two integers <b>N</b> and <b>K</b>: the total number of cores, and\n  the minimum number of cores that must succeed for the AI to function\n  properly. The second line contains one rational <b>U</b>: the number of\n  training units. The third line contains <b>N</b> rational numbers\n  <b>P<sub>i</sub></b>; the i-th of these gives the probability that the i-th\n  core will function properly. All of these probabilities are specified to\n  exactly four decimal places of precision.\n</p>\n\n<h3>Output</h3>\n<p>\n  For each test case, output one line containing <code>Case #x: y</code>, where\n  <code>x</code> is the test case number (starting from 1) and <code>y</code>\n  is the probability that the AI will function properly if the training units\n  are assigned optimally. <code>y</code> will be considered correct if it is\n  within an absolute or relative error of 10<sup>-6</sup> of the correct\n  answer. See the <a href=\"https://codingcompetitions.withgoogle.com/codejam/faq\" target=\"_blank\">FAQ</a> for an\n  explanation of what that means, and what formats of real numbers we accept.\n</p>\n\n<h3>Limits</h3>\n<p>\nMemory limit: 1 GB.<br/>\n  1 &le; <b>T</b> &le; 100.<br/>\n  1 &le; <b>N</b> &le; 50.<br/>\n  For all i, 0.0000 &le; <b>P<sub>i</sub></b> &le; 1.0000.<br/>\n  0.0000 &le; <b>U</b> &le; <b>N</b> - the sum of all <b>P<sub>i</sub></b>.\n    (There will not be more training units than can be used.)<br/>\n</p>\n\n<h4>Small dataset 1 (Test Set 1 - Visible)</h4>\n<p>\nTime limit: 20 seconds.<br/>\n  <b>K</b> = <b>N</b>.<br/> (All of the cores must function properly for the AI\n  to function properly.)\n</p>\n\n<h4>Small dataset 2 (Test Set 2 - Visible)</h4>\n<p>\nTime limit: 40 seconds.<br/>\n  1 &le; <b>K</b> &le; <b>N</b>.<br/>\n</p>\n\n\n  <h3>Sample</h3>\n  <div class=\"problem-io-wrapper\">\n  <table>\n  <tr>\n  <td>\n  <br/>\n  <span class=\"io-table-header\">Input</span>\n  <br/>&nbsp;\n  </td>\n  <td>\n  <br/>\n  <span class=\"io-table-header\">Output</span>\n  <br/>&nbsp;\n  </td>\n  </tr>\n  <tr>\n  <td>\n  <pre class=\"io-content\">4\n4 4\n1.4000\n0.5000 0.7000 0.8000 0.6000\n2 2\n1.0000\n0.0000 0.0000\n2 1\n0.0000\n0.9000 0.8000\n2 1\n0.1000\n0.4000 0.5000\n\n  </pre>\n  </td>\n  <td>\n  <pre class=\"io-content\">Case #1: 1.000000\nCase #2: 0.250000\nCase #3: 0.980000\nCase #4: 0.760000\n\n  </pre>\n  </td></tr></table>\n  </div>\n  \n\n<p>\n  Note that the last two sample cases would not appear in Small dataset 1.\n</p><p>\n  In Sample Case #1, we have enough training units to spend to give all cores\n  a success probability of 1, so the AI will certainly function properly.\n</p><p>\n  In Sample Case #2, both of the cores must function properly for the AI to\n  function properly, so we must give each core at least some training units.\n  The best option turns out to be to train each one up to 0.5. Then the\n  probability that the AI functions properly is 0.5 &times; 0.5 = 0.25. Any\n  other assignment is inferior; for instance, if we train one core to 0.9 and\n  the other core to 0.1, the probability of success is only 0.9 &times; 0.1 =\n  0.09.\n</p><p>\n  In Sample Case #3, we have no training units to spend, and at least one of\n  the two cores must function properly for the AI to function properly. We can\n  approach this by first calculating the probability that the AI does\n  <i>not</i> function properly, which happens only if both cores fail to\n  function properly. The probability that both cores fail is (1 - 0.9) &times;\n  (1 - 0.8) = 0.02. So the probability that at least one core functions\n  properly, and thus that the AI functions properly, is 1 - 0.02 = 0.98.\n</p><p>\n  In Sample Case #4, the optimal strategy is to give all the training units to\n  the second core. That makes the probability of at least one core functioning\n  properly 1 - (0.4 &times; 0.6) = 0.76. All other options are inferior; for\n  example, giving all the training units to the first core only yields 0.75,\n  and dividing them equally among the cores gives 0.7525.\n</p>\n","task_type":1,"task_type__str":"CODE_JAM","tests":[{"type":1,"type__str":"VISIBLE","value":15},{"type":1,"type__str":"VISIBLE","value":28}],"title":"Core Training","trial_input_type":1,"trial_input_type__str":"TEXT_FILE"},{"analysis":"<h2>Ample Syrup: Analysis</h2>\n<h3>Small dataset</h3>\n<p>\n  With at most ten pancakes to consider, we can easily enumerate and check all\n  subsets of size <b>K</b>, perhaps using a library function such as Python's\n  <code>itertools.combinations</code>. When we are considering a subset, the\n  statement's rules tell us exactly how to stack them: in nondecreasing radius\n  order from top to bottom. So all we need is a way to calculate a stack's\n  exposed pancake surface area.\n</p><p>\n  Except for the top pancake, any pancake that is not completely covered by the\n  one above it exposes a ring-shaped outer area of its upper surface. It is\n  possible to calculate and sum the areas of these rings, but there is a much\n  easier method. Observe that the exposed top areas of all pancakes in the\n  stack exactly add up to the top area of the bottom pancake in the stack. That\n  is, if you were to look down on the exact center of the stack, ignoring the\n  heights of the pancakes, the view would be indistinguishable from the top of\n  the bottom pancake. So the exposed surface area of a stack is equal to the\n  top area of the bottom pancake, plus the combined areas of all pancakes'\n  sides. This is &pi; &times; <b>R</b><sup>2</sup> for the bottom pancake,\n  plus the sum (over all pancakes in the stack) of 2 &times; &pi; &times;\n  <b>R<sub>i</sub></b> &times; <b>H<sub>i</sub></b>. The largest such sum that\n  we find after checking all possible pancake subsets is our answer.\n</p>\n<h3>Large dataset</h3>\n<p>\n  For the Large dataset, we cannot afford to check every possible subset, so we\n  need a better approach. Suppose that we choose a certain pancake P to be on\n  the bottom of our stack. Then every other pancake in the stack must have a\n  radius no larger than the radius of P. Recall from our area-calculating\n  simplification above that the other pancakes besides P effectively only\n  contribute their sides to the total exposed surface area, so we do not need\n  to think about their tops. So, out of the pancakes besides P, we should\n  choose the <b>K</b> - 1 of them that have the largest values of\n  <b>R<sub>i</sub></b> &times; <b>H<sub>i</sub></b>.\n</p><p>\n  So, we can try every pancake as a possible bottom; once we choose a possible\n  bottom, the criterion above tells us exactly which other pancakes we should\n  stack on top of it. We can simply search the list for these each time we try\n  a new bottom, given the low maximum value of <b>N</b>, but we can do better.\n  For example, we can start with one list of pancakes sorted in nonincreasing\n  order by side area, and another list of pancakes sorted in nonincreasing\n  order by radius. Then we can go through the list of possible radii in\n  decreasing order, treating each pancake in turn as the possible bottom; for\n  each one, we choose the first <b>K</b> - 1 pancakes from the list sorted by\n  side area. Whenever we encounter a pancake in the list sorted by side area\n  that comes earlier in the list sorted by radius than our current possible\n  bottom does, we can remove it forever from the list sorted by side area. It\n  is always safe to do this. If that pancake's radius is larger than the\n  radius of our possible bottom, we cannot use it now or ever again, since all\n  future possible bottoms will have a radius that is no larger. If that\n  pancake's radius is equal to the radius of our possible bottom, we have\n  already tried to use that pancake as a bottom previously (since it is earlier\n  in the list sorted by radius), so we have already checked an equivalent stack\n  in which pancakes of the same radius differed only in their order in the\n  stack. Of course, if we encounter our current possible bottom in the list\n  sorted by side area, we should remove that too, because we cannot use the\n  same pancake twice in a stack.\n</p><p>\n  This strategy drops the time complexity to O(<b>N</b> log <b>N</b> (for the\n  sorts) + <b>N</b> &times; <b>K</b>), which is effectively\n  O(<b>N</b><sup>2</sup>) in the worst case. We can further improve upon this\n  by storing our best set of <b>K</b> - 1 as a min heap / priority queue\n  bases on index in the radius list, so that we do not need to check\n  all <b>K</b> - 1 values each time to see whether they have \"expired\". This\n  drops the complexity to O(<b>N</b> log <b>N</b> + <b>K</b> log <b>K</b>),\n  which is equivalent to O(<b>N</b> log <b>N</b>).\n</p>\n","id":"0000000000201874","statement":"<h3>Problem</h3>\n<p>\n  The kitchen at the Infinite House of Pancakes has just received an order for\n  a stack of <b>K</b> pancakes! The chef currently has <b>N</b> pancakes\n  available, where <b>N</b> &ge; <b>K</b>. Each pancake is a cylinder, and\n  different pancakes may have different radii and heights.\n</p><p>\n  As the sous-chef, you must choose <b>K</b> out of the <b>N</b>\n  available pancakes, discard the others, and arrange those <b>K</b> pancakes\n  in a stack on a plate as follows. First, take the pancake that has the\n  largest radius, and lay it on the plate on one of its circular faces. (If\n  multiple pancakes have the same radius, you can use any of them.) Then, take\n  the remaining pancake with the next largest radius and lay it on top of that\n  pancake, and so on, until all <b>K</b> pancakes are in the stack and the\n  centers of the circular faces are aligned in a line perpendicular to the\n  plate, as illustrated by this example:\n</p><p>\n  <img alt=\"A stack of pancakes with varying radii and thicknesses, obeying the rules in the statement.\" src=\"https://codejam.googleapis.com/dashboard/get_file/AQj_6U29FPP06g0AC6E5YWbXSooo8bFSbjpbCZQ-5uOOC2cQ8FX5Yjl7MS6g2VpttCHU9imiXswyDUKupA8H8Q/pancake_stack.png\">\n</p><p>\n  You know that there is only one thing your diners love as much as they love\n  pancakes: syrup! It is best to maximize the total amount of exposed pancake\n  surface area in the stack, since more exposed pancake surface area means more\n  places to pour on delicious syrup. Any part of a pancake that is not touching\n  part of another pancake or the plate is considered to be exposed.\n</p><p>\n  If you choose the <b>K</b> pancakes optimally, what is the largest total\n  exposed pancake surface area you can achieve?\n</p>\n\n<h3>Input</h3>\n<p>\n  The first line of the input gives the number of test cases, <b>T</b>.\n  <b>T</b> test cases follow. Each begins with one line with two integers\n  <b>N</b> and <b>K</b>: the total number of available pancakes, and the size\n  of the stack that the diner has ordered. Then, <b>N</b> more lines follow.\n  Each contains two integers <b>R<sub>i</sub></b> and <b>H<sub>i</sub></b>:\n  the radius and height of the i-th pancake, in millimeters.\n</p>\n\n<h3>Output</h3>\n<p>\n  For each test case, output one line containing <code>Case #x: y</code>,\n  where <code>x</code> is the test case number (starting from 1) and\n  <code>y</code> is the maximum possible total exposed pancake surface area, in\n  millimeters squared. <code>y</code> will be considered correct if it is\n  within an absolute or relative error of 10<sup>-6</sup> of the correct\n  answer. See the <a href=\"https://codingcompetitions.withgoogle.com/codejam/faq\" target=\"_blank\">FAQ</a> for an\n  explanation of what that means, and what formats of real numbers we accept.\n</p>\n\n<h3>Limits</h3>\n<p>\nTime limit: 20 seconds per test set.<br/>\nMemory limit: 1 GB.<br/>\n  1 &le; <b>T</b> &le; 100.<br/>\n  1 &le; <b>K</b> &le; <b>N</b>.<br/>\n  1 &le; <b>R<sub>i</sub></b> &le; 10<sup>6</sup>, for all i.<br/>\n  1 &le; <b>H<sub>i</sub></b> &le; 10<sup>6</sup>, for all i.<br/>\n</p>\n\n<h4>Small dataset (Test Set 1 - Visible)</h4>\n<p>\n  1 &le; <b>N</b> &le; 10.<br/>\n</p>\n\n<h4>Large dataset (Test Set 2 - Hidden)</h4>\n<p>\n  1 &le; <b>N</b> &le; 1000.<br/>\n</p>\n\n\n  <h3>Sample</h3>\n  <div class=\"problem-io-wrapper\">\n  <table>\n  <tr>\n  <td>\n  <br/>\n  <span class=\"io-table-header\">Input</span>\n  <br/>&nbsp;\n  </td>\n  <td>\n  <br/>\n  <span class=\"io-table-header\">Output</span>\n  <br/>&nbsp;\n  </td>\n  </tr>\n  <tr>\n  <td>\n  <pre class=\"io-content\">4\n2 1\n100 20\n200 10\n2 2\n100 20\n200 10\n3 2\n100 10\n100 10\n100 10\n4 2\n9 3\n7 1\n10 1\n8 4\n\n  </pre>\n  </td>\n  <td>\n  <pre class=\"io-content\">Case #1: 138230.076757951\nCase #2: 150796.447372310\nCase #3: 43982.297150257\nCase #4: 625.176938064\n\n  </pre>\n  </td></tr></table>\n  </div>\n  \n\n<p>\n  In sample case #1, the \"stack\" consists only of one pancake. A stack of just\n  the first pancake would have an exposed area of &pi; &times;\n  <b>R<sub>0</sub></b><sup>2</sup> + 2 &times; &pi; * <b>R<sub>0</sub></b>\n  &times; <b>H<sub>0</sub></b> = 14000&pi; mm<sup>2</sup>. A stack of just the\n  second pancake would have an exposed area of 44000&pi; mm<sup>2</sup>. So it\n  is better to use the second pancake.\n</p><p>\n  In sample case #2, we can use both of the same pancakes from case #1. The\n  first pancake contributes its top area and its side, for a total of 14000&pi;\n  mm<sup>2</sup>. The second pancake contributes some of its top area (the\n  part not covered by the first pancake) and its side, for a total of 34000&pi;\n  mm<sup>2</sup>. The combined exposed surface area is 48000&pi;\n  mm<sup>2</sup>.\n</p><p>\n  In sample case #3, all of the pancakes have radius 100 and height 10. If we\n  stack two of these together, we effectively have a single new cylinder of\n  radius 100 and height 20. The exposed surface area is 14000&pi;\n  mm<sup>2</sup>.\n</p><p>\n  In sample case #4, the optimal stack uses the pancakes with radii of 8 and\n  9.\n</p>\n","task_type":1,"task_type__str":"CODE_JAM","tests":[{"type":1,"type__str":"VISIBLE","value":9},{"type":2,"type__str":"HIDDEN","value":16}],"title":"Ample Syrup","trial_input_type":1,"trial_input_type__str":"TEXT_FILE"},{"analysis":"<h2>Parenting Partnering: Analysis</h2>\n<p>\n  It is clear that whenever one parent has an activity, the other parent must\n  care for the baby throughout that activity. But how should Cameron and Jamie\n  divide up their remaining time after all activities are covered?\n</p>\n<h3>Small dataset</h3>\n<p>\n  In the Small dataset, there are at most two activities, so we can use\n  casework:\n</p>\n<ul>\n  <li>If only one parent has an activity, an optimal solution is to have the\n    other parent care for the baby in a continuous 720 minute block that includes\n    that activity. Then the parent with the activity can handle the other 720\n    minutes. So only 2 exchanges are required.</li>\n  <li>If both parents have one activity each, the same idea as above works.\n    It is always possible to choose some way to divide the 24-hour cycle\n    exactly in half, such that Cameron's activity falls completely within\n    Jamie's half and vice versa. So the answer is again 2.</li>\n  <li>If one parent (without loss of generality, we'll say it's Cameron) has\n    two activities, then they divide the 24-hour cycle such that there is a gap\n    between activity 1 and activity 2, and a gap between activity 2 and\n    activity 1. Jamie has to cover both activities. If one of these gaps is\n    empty (which can occur if the activities are back-to-back) or can be\n    completely filled in by Jamie, then the split the day in half strategy\n    works again and the answer is 2. But if the activities are too far apart\n    and/or too long, Jamie may not have enough remaining time to fill in either\n    gap; in that case, both gaps must contain a switch from Jamie to Cameron\n    and back, so the answer is 4. (We will explain later how we can fill in\n    such gaps without adding more exchanges than we need to, regardless of\n    how much time each parent contributes to filling in the gap.)\n</ul>\n<p>\n  It does not take much code to implement the above arguments. However, care\n  must be taken to handle midnight correctly when calculating the lengths of\n  the gaps in the third case.\n</p>\n<h3>Large dataset</h3>\n<p>\n  Let's consider a list of the activities, sorted by time. To gracefully handle\n  the midnight transition and the time before the first activity / after the\n  last activity, we will add a copy of the first activity to the end of the\n  list. In this list, each interval is surrounded by two activities. Some\n  intervals may be instantaneous transitions between activities that are\n  back-to-back (let's call these \"empty\"); the other intervals represent all of\n  the non-activity time. Each of these other intervals is either surrounded by\n  activities covered by different parents, or by activities covered by the same\n  parent.\n</p><p>\n  We have no decisions to make about the empty intervals, but we must count up\n  the exchanges they add. What about the different-parent intervals? For each,\n  we will have to add some time from one or both parents to cover the interval;\n  we can always do this optimally by starting with the time (if any) from the\n  parent covering the activity on the left, and ending with the time (if any)\n  from the parent covering the activity on the right. This strategy always\n  leaves us with just one exchange. We can do no better than that (since the\n  two different parents guaranteed that there would be at least one exchange),\n  and we have no reason to do worse than that. So we do not need to worry about\n  the different-parent intervals at all! We can assume that whatever time we\n  have available (from one or both parents) can fill them up without creating\n  any new exchanges.\n</p><p>\n  Same-parent intervals require some more thought. If we can fill one in with\n  time from the parent who is covering the endpoint activities, we can avoid an\n  exchange, whereas if we include any time at all from the other parent, we\n  will add <i>two</i> more exchanges. (We can avoid adding more than two by\n  putting the time from the other parent in in one continuous chunk.) We may\n  not be able to avoid the latter, depending on how much available time each\n  parent has left, but we should fill as many intervals with \"matching\" time as\n  we can, to minimize the number of new exchanges we create. Each interval\n  contributes equally to the number of possible exchanges, but the intervals\n  may have different lengths, and longer ones take up more of a parent's\n  available time. So our best strategy is to sort the list of Cameron-bounded\n  intervals and greedily fill in the shortest ones with Cameron time until we\n  do not have enough Cameron time left to fill in the shortest remaining\n  interval. Then, we do the same for the Jamie-bounded intervals. For every\n  interval we fail to fill in this way, we add two exchanges to our total.\n</p><p>\n  After we have handled the same-parent intervals, we are done and our current\n  total number of exchanges is our answer. Whatever remaining time we have from\n  one or both parents can safely go into the different-parent intervals without\n  creating any new exchanges. As explained above, we do not need to think about\n  the details; we leave those as an exercise for Cameron and Jamie.\n</p><p>\n  This method is O(<b>N</b> log <b>N</b>) (because of the required sorting\n  operations) and is easily fast enough for the Large dataset.\n</p>\n","id":"00000000002018fd","statement":"<h3>Problem</h3>\n<p>\n  Cameron and Jamie are longtime life partners and have recently become parents!\n  Being in charge of a baby, exciting as it is, is not without challenges.\n  Given that both parents have a scientific mind, they have decided to take a\n  scientific approach to baby care.\n</p><p>\n  Cameron and Jamie are establishing a daily routine and need to decide who\n  will be the main person in charge of the baby at each given time. They have\n  been equal partners their whole relationship, and they do not want to stop\n  now, so they decided that each of them will be in charge for exactly 12\n  hours (720 minutes) per day.\n</p><p>\n  Cameron and Jamie have other activities that they either need or want to\n  do on their own. Cameron has <b>A<sub>C</sub></b> of these and Jamie has\n  <b>A<sub>J</sub></b>. These activities always take place at the same times\n  each day. None of Cameron's activities overlap with Jamie's activities, so at\n  least one of the parents will always be free to take care of the baby.\n</p><p>\n  Cameron and Jamie want to come up with a daily baby care schedule such that:\n</p>\n<ul>\n  <li>Scheduled baby time must not interfere with a scheduled activity.\n    That is, during Cameron's activities, Jamie has to be in charge of the\n    baby, and vice versa.</li>\n  <li>Each of Cameron and Jamie must have exactly 720 minutes assigned to\n    them.</li>\n  <li>The number of exchanges &mdash; that is, the number of times the person\n    in charge of the baby changes from one partner to the other &mdash; must be\n    as small as possible.</li>\n</ul>\n<p>\n  For example, suppose that Jamie and Cameron have a single activity each:\n  Jamie has a morning activity from 9 am to 10 am, and Cameron has an afternoon\n  activity from 2 pm to 3 pm. One possible but suboptimal schedule would be for\n  Jamie to take care of the baby from midnight to 6 am and from noon to 6 pm,\n  and for Cameron to take care of the baby from 6 am to noon and 6 pm to\n  midnight. That fulfills the first two conditions, and requires a total of 4\n  exchanges, which happen at midnight, 6 am, noon and 6 pm. If there is an\n  exchange happening at midnight, it is counted exactly once, not zero or two\n  times.\n</p><p>\n  A better option would be for Cameron to take care of the baby from midnight\n  to noon, and Jamie to take care of the baby from noon to midnight. This\n  schedule also fulfills the first two conditions, but it uses only 2\n  exchanges, which is the minimum possible.\n</p><p>\n  Given Cameron's and Jamie's lists of activities, and the restrictions above,\n  what is the minimum possible number of exchanges in a daily schedule?\n</p>\n\n<h3>Input</h3>\n<p>\n  The first line of the input gives the number of test cases, <b>T</b>.\n  <b>T</b> test cases follow. Each test case starts with a line containing two\n  integers <b>A<sub>C</sub></b> and <b>A<sub>J</sub></b>, the number of\n  activities that Cameron and Jamie have, respectively. Then,\n  <b>A<sub>C</sub></b> + <b>A<sub>J</sub></b> lines follow. The first\n  <b>A<sub>C</sub></b> of these lines contain two integers <b>C<sub>i</sub></b>\n  and <b>D<sub>i</sub></b> each. The i-th of Cameron's activities starts\n  exactly <b>C<sub>i</sub></b> minutes after the start of the day at midnight\n  and ends exactly <b>D<sub>i</sub></b> minutes after the start of the day at\n  midnight (taking exactly <b>D<sub>i</sub></b> - <b>C<sub>i</sub></b> minutes).\n  The last <b>A<sub>J</sub></b> of these lines contain two integers\n  <b>J<sub>i</sub></b> and <b>K<sub>i</sub></b> each, representing the starting\n  and ending time of one of Jamie's activities, in minutes counting from the\n  start of the day at midnight (same format as Cameron's). No activity spans two\n  days, and no two activities overlap (except that one might end exactly as another\n  starts, but an exchange can still occur at that time).\n</p>\n\n<h3>Output</h3>\n<p>\n  For each test case, output one line containing <code>Case #x: y</code>,\n  where <code>x</code> is the test case number (starting from 1) and\n  <code>y</code> the minimum possible number of exchanges, as described in the\n  statement.\n</p>\n\n<h3>Limits</h3>\n<p>\nTime limit: 20 seconds per test set.<br/>\nMemory limit: 1 GB.<br/>\n  1 &le; <b>T</b> &le; 100.<br/>\n  0 &le; <b>C<sub>i</sub></b> &lt; <b>D<sub>i</sub></b> &le; 24 &times; 60,\n    for all i.<br/>\n  0 &le; <b>J<sub>i</sub></b> &lt; <b>K<sub>i</sub></b> &le; 24 &times; 60,\n    for all i.<br/>\n  Any two of the intervals of {[<b>C<sub>i</sub></b>, <b>D<sub>i</sub></b>)\n    for all i} union {[<b>J<sub>i</sub></b>, <b>K<sub>i</sub></b>) for all i}\n  have an empty intersection. (The intervals are closed on the left and open\n  on the right, which ensures that two exactly consecutive intervals have\n  nothing in between but do not overlap.)<br/>\n  sum of {<b>D<sub>i</sub></b> - <b>C<sub>i</sub></b> for all i} &le; 720.<br/>\n  sum of {<b>K<sub>i</sub></b> - <b>J<sub>i</sub></b> for all i} &le; 720.<br/>\n</p>\n\n<h4>Small dataset (Test Set 1 - Visible)</h4>\n<p>\n  0 &le; <b>A<sub>C</sub></b> &le; 2.<br/>\n  0 &le; <b>A<sub>J</sub></b> &le; 2.<br/>\n  1 &le; <b>A<sub>C</sub></b> + <b>A<sub>J</sub></b> &le; 2.<br/>\n</p>\n\n<h4>Large dataset (Test Set 2 - Hidden)</h4>\n<p>\n  0 &le; <b>A<sub>C</sub></b> &le; 100.<br/>\n  0 &le; <b>A<sub>J</sub></b> &le; 100.<br/>\n  1 &le; <b>A<sub>C</sub></b> + <b>A<sub>J</sub></b> &le; 200.<br/>\n</p>\n\n\n  <h3>Sample</h3>\n  <div class=\"problem-io-wrapper\">\n  <table>\n  <tr>\n  <td>\n  <br/>\n  <span class=\"io-table-header\">Input</span>\n  <br/>&nbsp;\n  </td>\n  <td>\n  <br/>\n  <span class=\"io-table-header\">Output</span>\n  <br/>&nbsp;\n  </td>\n  </tr>\n  <tr>\n  <td>\n  <pre class=\"io-content\">5\n1 1\n540 600\n840 900\n2 0\n900 1260\n180 540\n1 1\n1439 1440\n0 1\n2 2\n0 1\n1439 1440\n1438 1439\n1 2\n3 4\n0 10\n1420 1440\n90 100\n550 600\n900 950\n100 150\n1050 1400\n\n  </pre>\n  </td>\n  <td>\n  <pre class=\"io-content\">Case #1: 2\nCase #2: 4\nCase #3: 2\nCase #4: 4\nCase #5: 6\n\n  </pre>\n  </td></tr></table>\n  </div>\n  \n\n<p>\n  Note that Cases #4 and #5 would not appear in the Small dataset.\n</p><p>\n  Case #1 is the one described in the problem statement.\n</p><p>\n  In Case #2, Jamie must cover for all of Cameron's activity time, and then\n  Cameron must cover all the remaining time. This schedule entails four\n  exchanges.\n</p><p>\n  In Case #3, there is an exchange at midnight, from Cameron to Jamie. No\n  matter how the parents divide up the remaining 1438 non-activity minutes of\n  the day, there must be at least one exchange from Jamie to Cameron, and there\n  is no reason to add more exchanges than that.\n</p><p>\n  In Case #4, note that back-to-back activities can exist for the same partner\n  or different partners. There is no exchange at midnight because Cameron has\n  activities both right before and right after that time. However, the schedule\n  needs to add some time for Cameron in between Jamie's activities, requiring a\n  total of 4 exchanges. Notice that it is optimal to add a single interval\n  for Cameron of length 718 somewhere between minutes 2 and 1438, but the\n  exact position of that added interval does not impact the number of\n  exchanges, so there are multiple optimal schedules.\n</p><p>\n  In Case #5, a possible optimal schedule is to assign Cameron to the intervals\n  (in minutes) 100-200, 500-620, and 900-1400.\n</p>\n","task_type":1,"task_type__str":"CODE_JAM","tests":[{"type":1,"type__str":"VISIBLE","value":12},{"type":2,"type__str":"HIDDEN","value":20}],"title":"Parenting Partnering","trial_input_type":1,"trial_input_type__str":"TEXT_FILE"}],"ticket":{"challenge_id":"0000000000201842","type":1,"type__str":"SPECTATOR"},"title":"Round 1C 2017"},"languages":[{"id":1,"id__str":"BASH","name":"Bash"},{"id":2,"id__str":"C","name":"C (GCC)"},{"id":11,"id__str":"CSHARP","name":"C# (Mono)"},{"id":3,"id__str":"CPP","name":"C++17 (G++)"},{"id":19,"id__str":"CLOJURE","name":"Clojure"},{"id":24,"id__str":"D","name":"D (GDC)"},{"id":32,"id__str":"DART","name":"Dart"},{"id":28,"id__str":"FSHARP","name":"F# (Mono)"},{"id":6,"id__str":"GO","name":"Go 1.11.6"},{"id":20,"id__str":"GROOVY","name":"Groovy"},{"id":12,"id__str":"HASKELL","name":"Haskell (GHC)"},{"helper_text":"Please name your main class \"Solution\" (uppercase S) and do not declare a package.","id":4,"id__str":"JAVA","name":"Java 11 (OpenJDK)"},{"id":10,"id__str":"JAVASCRIPT","name":"JavaScript (Node.js)"},{"id":29,"id__str":"JULIA","name":"Julia"},{"id":22,"id__str":"KOTLIN","name":"Kotlin"},{"id":23,"id__str":"LISP","name":"Lisp (SBCL)"},{"id":30,"id__str":"LUA","name":"Lua"},{"id":18,"id__str":"OCAML","name":"OCaml"},{"id":31,"id__str":"OBJECTIVEC","name":"Objective-C (GNU)"},{"id":15,"id__str":"OCTAVE","name":"Octave"},{"id":9,"id__str":"PHP","name":"PHP"},{"id":21,"id__str":"PASCAL","name":"Pascal (FPC)"},{"id":14,"id__str":"PERL","name":"Perl"},{"id":34,"id__str":"PYPY3","name":"PyPy 3"},{"id":7,"id__str":"PYTHON3","name":"Python 3.7"},{"id":25,"id__str":"R","name":"R"},{"id":8,"id__str":"RUBY","name":"Ruby"},{"id":17,"id__str":"RUST","name":"Rust"},{"helper_text":"Please name your main class \"Solution\" (uppercase S).","id":13,"id__str":"SCALA","name":"Scala"},{"id":16,"id__str":"SWIFT","name":"Swift"},{"id":33,"id__str":"TYPESCRIPT","name":"TypeScript (Node.js)"},{"id":27,"id__str":"VISUALBASIC","name":"Visual Basic (Mono)"}]}
